{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Munish_Khurana_lab1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCo04WBuJtcG"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJQABurBC58O",
        "outputId": "9932f7b1-a9e9-41fe-8b5a-73fe31c9fc6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "fname = 'facebook_comments.csv'\n",
        "df_train = pd.read_csv(fname, header=None, names=['text','sentiment'], encoding='iso-8859-1' , lineterminator='\\n' )\n",
        "\n",
        "#df_train.head()\n",
        "\n",
        "sent = {'positive' : 2, 'neutral' : 1, 'negative':0}\n",
        "df_train['labels'] = df_train['sentiment'].str.strip().map(sent)\n",
        "\n",
        "#df_train.head()\n",
        "\n",
        "training_texts = df_train.text.values\n",
        "labels = df_train.labels.values\n",
        "#print(labels.shape)\n",
        "\n",
        "#print(training_texts)\n",
        "df_train.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Heres a single  to add  to Kindle. Just read t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you tire of Non-Fiction.. Check out http://...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ghost of Round Island is supposedly nonfiction.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why is Barnes and Nobles version of the Kindle...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Maria:  Do you mean the Nook?  Be careful  bo...</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment  labels\n",
              "0  Heres a single  to add  to Kindle. Just read t...    neutral       1\n",
              "1  If you tire of Non-Fiction.. Check out http://...    neutral       1\n",
              "2   Ghost of Round Island is supposedly nonfiction.     neutral       1\n",
              "3  Why is Barnes and Nobles version of the Kindle...   negative       0\n",
              "4  @Maria:  Do you mean the Nook?  Be careful  bo...   positive       2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnednK2sBpWr"
      },
      "source": [
        "Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oT8T8ljFbjB",
        "outputId": "2aba0fa5-ef6b-40d3-c190-5235c63c9f42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "\n",
        "vectorizer=TfidfVectorizer(stop_words='english', max_features=500)\n",
        "instances=vectorizer.fit_transform(training_texts)\n",
        "X=instances\n",
        "Y=np.array(labels)\n",
        "\n",
        "print(X.shape,',',Y.shape)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 500) , (1999,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBi7yeuUJwqG"
      },
      "source": [
        "Traditional machine Learning Models: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2wtP3yrGhNG",
        "outputId": "06d75474-a5be-42d1-8d02-73029a6e1398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "kfold=KFold(n_splits=10,shuffle=True,random_state=2020)\n",
        "rf_model=RandomForestClassifier(random_state=2020,max_depth=2,criterion='entropy')\n",
        "rf_cvscores= []\n",
        "\n",
        "\n",
        "for train,test in kfold.split(X):\n",
        "  rf_model.fit(X[train],Y[train])\n",
        "  rf_acc=rf_model.score(X[test],Y[test])\n",
        "  rf_cvscores.append(rf_acc)\n",
        "\n",
        "\n",
        "print(\"Random Forest - mean: %.4f%%  (std:+/- %.4f%%)\" % (np.mean(rf_cvscores)*100, np.std(rf_cvscores)*100))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest - mean: 64.1332%  (std:+/- 2.0919%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vjygRGFJfNU"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAg4Ry3NJk-q"
      },
      "source": [
        "Fully Connected FeedForward Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsOnC1HEJrdV"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.optim as optim\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xiRe7hgK_Pa"
      },
      "source": [
        "Build the train loader and validation loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVKGbpE9U0kY"
      },
      "source": [
        "epochs=5\n",
        "learn=1e-4\n",
        "indim=X.shape[1]\n",
        "outdim=3\n",
        "drate=0.7\n",
        "batch_size=20"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ClFwtVoLElF"
      },
      "source": [
        "X_tensor=torch.from_numpy(X.toarray())\n",
        "Y_tensor=torch.from_numpy(Y)\n",
        "\n",
        "\n",
        "dataset=TensorDataset(X_tensor,Y_tensor)\n",
        "train_size=int(0.8*len(dataset))\n",
        "val_size=len(dataset)-train_size\n",
        "train_dataset, val_dataset=torch.utils.data.random_split(dataset,[train_size,val_size])\n",
        "#creating training loader and validation loader\n",
        "train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "val_loader=DataLoader(val_dataset,batch_size=batch_size,shuffle=True)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK1L6zTKNCaH"
      },
      "source": [
        "Build the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3OZa8onNFCe"
      },
      "source": [
        "class SentimentNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, dropout_rate):\n",
        "    \n",
        "        super(SentimentNetwork,self).__init__()\n",
        "        self.fc1=nn.Linear(500,100)\n",
        "        self.dropout_rate=nn.Dropout(dropout_rate)\n",
        "        self.fc2=nn.Linear(100,50)\n",
        "        self.fc3=nn.Linear(50,3)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=self.dropout_rate(x)\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=self.fc3(x)\n",
        "        return x\n",
        "# create a model\n",
        "#model = SentimentNetwork(indim,outdim,drate)\n",
        "#print(model)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX51jvDjV_1R",
        "outputId": "9090ca8f-05e4-48e8-956f-ddbb7e8f7128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model = SentimentNetwork(indim, outdim, drate)\n",
        "#print(model)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learn)\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "\n",
        "#model=model.float() \n",
        "print(model)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentNetwork(\n",
            "  (fc1): Linear(in_features=500, out_features=100, bias=True)\n",
            "  (dropout_rate): Dropout(p=0.7, inplace=False)\n",
            "  (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
            "  (fc3): Linear(in_features=50, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iBsPn-V1eYA"
      },
      "source": [
        "# define a training process function\n",
        "from torch.autograd import Variable\n",
        "def train(model, train_loader, optimizer, criterion):\n",
        "    acc=0\n",
        "    epoch_loss, epoch_acc = 0.0,0.0 # the loss and accuracy for each epoch\n",
        "    model.train()\n",
        "    for idx,(batch_x,batch_y) in enumerate(train_loader):\n",
        "  ####for i,data in enumerate(train_loader,0):\n",
        "    ####inputs,labels=data\n",
        "    ####inputs,labels=Variable(inputs),Variable(labels)\n",
        "\n",
        "  #(batch_x,batch_y) in train_loader:\n",
        "        batch_x=Variable(batch_x)\n",
        "        batch_y=Variable(batch_y)\n",
        "\n",
        "  #predictions.detach().numpu()\n",
        "  #calculate the loss using predicted output and the trurh\n",
        "  #acc=calculate the accuracy from this batch_x\n",
        "\n",
        "  #update parameters: optimiser.step()\n",
        "          #zero  gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "  #get the predicted outputs for the batch_x\n",
        "        output=model(batch_x.float())\n",
        "\n",
        "#Calculate loss using the above defined criteria using predicted output and the truth\n",
        "        loss=criterion(output.float(),batch_y.long())\n",
        "  \n",
        "  \n",
        "  #backpropogate #loss.backward()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "  #prediction for the model      \n",
        "        prediction = output.data.max(1)[1]      \n",
        "        acc = prediction.eq(batch_y.data).sum()\n",
        "      #print(loss)\n",
        "      #return loss\n",
        " #Calculate loss for Epoch     \n",
        "        epoch_loss += loss.item()/20\n",
        "#Calculate Accuracy for Epoch        \n",
        "        epoch_acc += acc.item()/20     \n",
        "      #print(epoch_loss)\n",
        "    return epoch_loss/idx, epoch_acc/idx\n",
        "  #epoch+=loss.item()\n",
        "  #epoch_acc+acc \n",
        "\n",
        "    \n",
        "def evaluate(model, val_loader, criterion):\n",
        "    acc=0\n",
        "    epoch_loss, epoch_acc = 0.0,0.0  \n",
        "  \n",
        "    model.eval()\n",
        "  \n",
        "    with torch.no_grad():\n",
        "  \n",
        "   # the loss and accuracy for each epoch\n",
        "        \n",
        "        for batch_x,batch_y in val_loader:\n",
        "            batch_x=Variable(batch_x)\n",
        "            batch_y=Variable(batch_y)\n",
        "      #zero  gradient\n",
        "      #get the predicted outputs for the batch_x\n",
        "      #predictions.detach().numpu()\n",
        "      #calculate the loss using predicted output and the trurh\n",
        "      #acc=calculate the accuracy from this batch_x\n",
        "    \n",
        "      #update parameters: optimiser.step()\n",
        "            #optimizer.zero_grad()\n",
        "\n",
        "  #Create model based on batch_x values   \n",
        "            output=model(batch_x.float())\n",
        "#calculate the loss for the validation set using predicted output and the truth\n",
        "            loss=criterion(output.float(),batch_y.long())\n",
        "            \n",
        "            prediction =output.data.max(1)[1]      \n",
        " #Calculate accuracy for the model           \n",
        "            acc = prediction.eq(batch_y.data).sum()\n",
        "            \n",
        "          \n",
        "    #   print(loss)\n",
        "    #Calculate the \n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()      \n",
        "      #  print(epoch_loss)\n",
        "\n",
        "    return epoch_loss/len(val_loader.dataset), epoch_acc/len(val_loader.dataset)\n",
        "    \n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIRrNx_b-PPR"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrXdHGFGdbAQ"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmzvGKCmVdxl",
        "outputId": "d0456f1d-2e03-45b3-a111-ce01b0785b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "\n",
        "#epochs=5\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc =train(model, train_loader, optimizer,criterion)\n",
        "    valid_loss, valid_acc=evaluate(model, val_loader, criterion)\n",
        "\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.4f} |  Val. Acc: {valid_acc:.4f}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 0.0528 | Train Acc: 0.6500\n",
            "\t Val. Loss: 0.0522 |  Val. Acc: 0.6325\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.0527 | Train Acc: 0.6506\n",
            "\t Val. Loss: 0.0521 |  Val. Acc: 0.6325\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.0527 | Train Acc: 0.6513\n",
            "\t Val. Loss: 0.0520 |  Val. Acc: 0.6325\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.0526 | Train Acc: 0.6513\n",
            "\t Val. Loss: 0.0520 |  Val. Acc: 0.6325\n",
            "Epoch: 05\n",
            "\tTrain Loss: 0.0526 | Train Acc: 0.6513\n",
            "\t Val. Loss: 0.0519 |  Val. Acc: 0.6325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDEXWWXLPAs6"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynHikTNQSTkE"
      },
      "source": [
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}