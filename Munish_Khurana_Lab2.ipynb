{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of BUDT758 Lab2(1000 images).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrucsELzfeIe",
        "outputId": "3a355ff5-520c-418d-b9f3-b88bbf8c8f4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import files, drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpwq44jhjFUo",
        "outputId": "536e9597-5c48-4cbe-8205-de710dd298f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# this is yourpart create a CNN model for 10-class digit recognition classification problem\n",
        "#create/define a CNN model for handwriting digit recognition problem\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super().__init__()\n",
        "    \n",
        "    #define first conv layer(input channel:1, output_channel:6, filter_size:5*5)\n",
        "    #define pooling layer(2*2)\n",
        "    #define second conv layer(input channel:6, output_channel:16, filter_size:5*5)\n",
        "    #define a sub fully connected feedforward network\n",
        "    #hidden size (1):120\n",
        "    #hidden size(2): 84\n",
        "    #  output size: 10\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #define/add a cov layer\n",
        "  #1*6*    5*5\n",
        "    self.conv1 = nn.Conv2d(1, 6, 5) #After 1st conv 6*24*24\n",
        "    self.pool = nn.MaxPool2d(2, 2)  #6*12*12\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)  #16*8*8->After pool 16*4*4\n",
        "    self.fc1 = nn.Linear(16*4*4, 120) #ourinput image is 28*28,\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3=nn.Linear(84,10)\n",
        "    self.do1 = nn.Dropout(0.5)\n",
        "\n",
        "#forward\n",
        "# x-->conv1-->relu-->pooling-->conv2-->relu-->pooling-->fullyconnected\n",
        " \n",
        " \n",
        "  def forward(self, x):\n",
        "    x=self.pool(F.relu(self.conv1(x)))\n",
        "    self.do1 = nn.Dropout(0.5)\n",
        "    x=self.pool(F.relu(self.conv2(x)))\n",
        "    self.do1 = nn.Dropout(0.5)\n",
        "    x=x.view(-1,self.num_flat_features(x))\n",
        "    x=F.relu(self.fc1(x))\n",
        "    self.do1 = nn.Dropout(0.5)\n",
        "    x=F.relu(self.fc2(x))\n",
        "    self.do1 = nn.Dropout(0.5)\n",
        "    x=F.log_softmax(self.fc3(x))\n",
        "    return x\n",
        "\n",
        "    \n",
        "  def num_flat_features(self, x):\n",
        "    size = x.size()[1:]\n",
        "    num_features=1\n",
        "    for s in size:\n",
        "      num_features*= s\n",
        "\n",
        "    return num_features\n",
        "    \n",
        "net=Net().to(device)\n",
        "print(net)\n",
        "\n",
        "params=list(net.parameters())\n",
        "for i in range(len(params)):\n",
        "  print(params[i].size())\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            "  (do1): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "torch.Size([6, 1, 5, 5])\n",
            "torch.Size([6])\n",
            "torch.Size([16, 6, 5, 5])\n",
            "torch.Size([16])\n",
            "torch.Size([120, 256])\n",
            "torch.Size([120])\n",
            "torch.Size([84, 120])\n",
            "torch.Size([84])\n",
            "torch.Size([10, 84])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nY13FhxoV3U"
      },
      "source": [
        "#Create a customize Dataset\n",
        "#The torch provide you with thw dataset class we want to inherit it(create a subclass) to create my own customized dataset\n",
        "#Within my dataset I have many instances, each instance may contain properties\n",
        "#Each instance in customized dataset to have 2 field 1 is the image itself and the other is the label\n",
        "#Safe each istance as a dictionary with each instance 2 value pairs  \n",
        "\n",
        "import os \n",
        "import glob #Design for filr opwerations \n",
        "import numpy as np  #package to process images. it can convert image to Numpy array\n",
        "from skimage import io  \n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "#override __init__,__len__,and __getitem__ methods\n",
        "\n",
        "\n",
        "\n",
        "class MNISTDatasets(Dataset):\n",
        "#MNISTDataset is a subclass of Dataset\n",
        "#Override __init__,__len__, and __getitem__ methods\n",
        "  \n",
        "  def __init__(self,dir,transform=None):\n",
        "    self.dir=dir  #for example: /content/drive/My Drive/MNIST/trainingset/1/\n",
        "    self.transform=transform\n",
        "\n",
        "  def __len__(self):\n",
        "    files=glob.glob(self.dir+'/*.jpg')[:1000]\n",
        "    return len(files)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx=idx.tolist()\n",
        "      #provide index to images\n",
        "\n",
        "    all_files=glob.glob(self.dir+'/*.jpg')[:1000] #return a list of file names\n",
        "    img_fname =os.path.join(self.dir,all_files[idx]) #obtain a absolute path to that file with index idx\n",
        "    image=io.imread(img_fname) # to a numpy array for that image \n",
        "\n",
        "    digit=int(self.dir.split('/')[-1].strip())  # /content/drive/My Drive/MNIST/trainingset/1/\n",
        "    label=np.array(digit)\n",
        "    sample={'image':image, 'label':label}\n",
        "\n",
        "    if self.transform:\n",
        "      sample=self.transform(sample)\n",
        "\n",
        "    return sample\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWmVc228oNZa"
      },
      "source": [
        "# create/define a customized transformation for each instance in the dataset\n",
        "#Why rescale?\n",
        "# Size of all input image may not be the same , some images are of the size 28*8 and some images are of the size 28*30 \n",
        "#The sizes need to be consistant otherwise it cannot be put in the same model\n",
        "\n",
        "from skimage import transform \n",
        "from torchvision import transforms, utils\n",
        "\n",
        "class Rescale(object):\n",
        "\n",
        "  def __init__(self,output_size):\n",
        "    assert isinstance(output_size,(int,tuple)) #Check Output size must be either integer or tuple\n",
        "    self.output_size=output_size\n",
        "  \n",
        "  def __call__(self,sample):\n",
        "    image, label = sample['image'], sample['label'] #image is a numpy array #label is a numpy array but within that ther is only 1 dimension\n",
        "    h, w = image.shape[:2]  #Get the last 2 dimension\n",
        "    #no of rows(height) and number of column(w) from the numpy array\n",
        "    if isinstance(self.output_size,int):\n",
        "      if h>w: \n",
        "        new_h, new_w =self.output_size*h/w, self.output_size  \n",
        "      else:\n",
        "        new_h, new_w =self.output_size, self.output_size*w/h\n",
        "    else:\n",
        "      new_h, new_w = self.output_size\n",
        "\n",
        "    new_h, new_w= int(new_h),int(new_w)\n",
        "    \n",
        "    new_img= transform.resize(image, (new_h,new_w)) #Resize the image using new_h and new_w\n",
        "\n",
        "    return{'image':new_img,'label':label} #Return a dictionary\n",
        "\n",
        "class ToTensor(object): #Convert every instance to a Tensor\n",
        "  def __call__(self, sample):\n",
        "    image, label=sample['image'], sample['label']\n",
        "\n",
        "    image=image.reshape((1,image.shape[0],image.shape[1])) #3D to use it for CNN add a channel 1\n",
        "\n",
        "    return {'image':torch.from_numpy(image), 'label': torch.from_numpy(label)} #Convert into tensor\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwFqsuKQYjbo",
        "outputId": "d69f3054-1ca4-4692-f002-a7f13225c170",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# create train/val dataloader\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "batch_size = 32\n",
        "list_datasets=[]\n",
        "for i in range(10):\n",
        "  cur_ds = MNISTDatasets('/content/drive/My Drive/MNIST/trainingset/'+str(i), transform=transforms.Compose([Rescale(28),ToTensor()]))\n",
        "  list_datasets.append(cur_ds)  #10 seperate datasets\n",
        "\n",
        "dataset = torch.utils.data.ConcatDataset(list_datasets) #Combine the 10 different datasets\n",
        "print(len(dataset))\n",
        "#1000 instances Each instance is a dictionary with 2 key value pair 1st is image 2nd is label \n",
        "#Value for 1st key value pair is a tensor with dimension 1*28*28 the label tensor is 1*1\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv3sH5iSsyX-",
        "outputId": "a2752bca-4f3b-4176-9e88-5974f7650d0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_size=int(len(dataset)*0.7)\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset,[train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=1)\n",
        "val_dataloader= DataLoader(val_dataset,batch_size,shuffle=True,num_workers=1)\n",
        "print(train_size)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPXJ8Pln9ERP"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSYet1C-e6fT",
        "outputId": "77f50567-2f9e-42c9-95ac-b5e212e3eeab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#training/validation\n",
        "\n",
        "epochs =20\n",
        "learning_rate =1e-3\n",
        "optimizer = optim.Adam(net.parameters(),lr=learning_rate, weight_decay=1e-5)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  net.train() #update parameters\n",
        "  running_loss =0.0\n",
        "  for b, samples in enumerate(train_dataloader):\n",
        "    inputs,targets=samples['image'].to(device, dtype=torch.float), samples['label'].to(device,dtype=torch.long)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs,targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if (b+1)%10 == 0:\n",
        "      print('epoch %d, batch: %d, training loss: %.3f'%(epoch+1, b+1, running_loss/10)) #For every 10 batches\n",
        "      running_loss =0.0 #Reset running_loss\n",
        "   #validation\n",
        "  net.eval()\n",
        "  correct = [0.0]*10\n",
        "  total = [0.]*10\n",
        "  classes=range(10)\n",
        "   \n",
        "\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for b, data in enumerate(val_dataloader):\n",
        "      images, labels = data['image'].to(device,dtype=torch.float), data['label'].to(device,dtype=torch.long)\n",
        "      outputs=net(images)\n",
        "\n",
        "      _,predicted = torch.max(outputs,1)\n",
        "      c=(predicted == labels)\n",
        "      for i in range(len(labels)):\n",
        "        label=labels[i]\n",
        "        correct[label] +=c[i].item()\n",
        "        total[label]+=1 \n",
        "\n",
        "  for i in range(10):\n",
        "      print('\\t Validation accuracy for digit %d: %.2f'% (classes[i], 100*correct[i]/total[i]))          \n",
        "\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1, batch: 10, training loss: 2.299\n",
            "epoch 1, batch: 20, training loss: 2.271\n",
            "epoch 1, batch: 30, training loss: 2.185\n",
            "epoch 1, batch: 40, training loss: 1.942\n",
            "epoch 1, batch: 50, training loss: 1.494\n",
            "epoch 1, batch: 60, training loss: 1.001\n",
            "epoch 1, batch: 70, training loss: 0.919\n",
            "epoch 1, batch: 80, training loss: 0.787\n",
            "epoch 1, batch: 90, training loss: 0.801\n",
            "epoch 1, batch: 100, training loss: 0.623\n",
            "epoch 1, batch: 110, training loss: 0.545\n",
            "epoch 1, batch: 120, training loss: 0.425\n",
            "epoch 1, batch: 130, training loss: 0.399\n",
            "epoch 1, batch: 140, training loss: 0.488\n",
            "epoch 1, batch: 150, training loss: 0.415\n",
            "epoch 1, batch: 160, training loss: 0.344\n",
            "epoch 1, batch: 170, training loss: 0.412\n",
            "epoch 1, batch: 180, training loss: 0.303\n",
            "epoch 1, batch: 190, training loss: 0.409\n",
            "epoch 1, batch: 200, training loss: 0.336\n",
            "epoch 1, batch: 210, training loss: 0.399\n",
            "\t Validation accuracy for digit 0: 96.93\n",
            "\t Validation accuracy for digit 1: 97.32\n",
            "\t Validation accuracy for digit 2: 86.21\n",
            "\t Validation accuracy for digit 3: 81.76\n",
            "\t Validation accuracy for digit 4: 97.70\n",
            "\t Validation accuracy for digit 5: 89.72\n",
            "\t Validation accuracy for digit 6: 92.38\n",
            "\t Validation accuracy for digit 7: 91.99\n",
            "\t Validation accuracy for digit 8: 84.36\n",
            "\t Validation accuracy for digit 9: 62.96\n",
            "epoch 2, batch: 10, training loss: 0.288\n",
            "epoch 2, batch: 20, training loss: 0.263\n",
            "epoch 2, batch: 30, training loss: 0.280\n",
            "epoch 2, batch: 40, training loss: 0.255\n",
            "epoch 2, batch: 50, training loss: 0.278\n",
            "epoch 2, batch: 60, training loss: 0.282\n",
            "epoch 2, batch: 70, training loss: 0.293\n",
            "epoch 2, batch: 80, training loss: 0.217\n",
            "epoch 2, batch: 90, training loss: 0.292\n",
            "epoch 2, batch: 100, training loss: 0.284\n",
            "epoch 2, batch: 110, training loss: 0.260\n",
            "epoch 2, batch: 120, training loss: 0.233\n",
            "epoch 2, batch: 130, training loss: 0.241\n",
            "epoch 2, batch: 140, training loss: 0.178\n",
            "epoch 2, batch: 150, training loss: 0.216\n",
            "epoch 2, batch: 160, training loss: 0.276\n",
            "epoch 2, batch: 170, training loss: 0.312\n",
            "epoch 2, batch: 180, training loss: 0.293\n",
            "epoch 2, batch: 190, training loss: 0.238\n",
            "epoch 2, batch: 200, training loss: 0.150\n",
            "epoch 2, batch: 210, training loss: 0.195\n",
            "\t Validation accuracy for digit 0: 95.90\n",
            "\t Validation accuracy for digit 1: 98.33\n",
            "\t Validation accuracy for digit 2: 96.21\n",
            "\t Validation accuracy for digit 3: 93.16\n",
            "\t Validation accuracy for digit 4: 87.87\n",
            "\t Validation accuracy for digit 5: 93.62\n",
            "\t Validation accuracy for digit 6: 95.56\n",
            "\t Validation accuracy for digit 7: 92.28\n",
            "\t Validation accuracy for digit 8: 91.64\n",
            "\t Validation accuracy for digit 9: 94.61\n",
            "epoch 3, batch: 10, training loss: 0.182\n",
            "epoch 3, batch: 20, training loss: 0.183\n",
            "epoch 3, batch: 30, training loss: 0.165\n",
            "epoch 3, batch: 40, training loss: 0.241\n",
            "epoch 3, batch: 50, training loss: 0.133\n",
            "epoch 3, batch: 60, training loss: 0.180\n",
            "epoch 3, batch: 70, training loss: 0.119\n",
            "epoch 3, batch: 80, training loss: 0.141\n",
            "epoch 3, batch: 90, training loss: 0.204\n",
            "epoch 3, batch: 100, training loss: 0.192\n",
            "epoch 3, batch: 110, training loss: 0.159\n",
            "epoch 3, batch: 120, training loss: 0.183\n",
            "epoch 3, batch: 130, training loss: 0.155\n",
            "epoch 3, batch: 140, training loss: 0.197\n",
            "epoch 3, batch: 150, training loss: 0.163\n",
            "epoch 3, batch: 160, training loss: 0.127\n",
            "epoch 3, batch: 170, training loss: 0.133\n",
            "epoch 3, batch: 180, training loss: 0.104\n",
            "epoch 3, batch: 190, training loss: 0.203\n",
            "epoch 3, batch: 200, training loss: 0.188\n",
            "epoch 3, batch: 210, training loss: 0.242\n",
            "\t Validation accuracy for digit 0: 99.32\n",
            "\t Validation accuracy for digit 1: 98.66\n",
            "\t Validation accuracy for digit 2: 93.10\n",
            "\t Validation accuracy for digit 3: 93.81\n",
            "\t Validation accuracy for digit 4: 97.70\n",
            "\t Validation accuracy for digit 5: 97.16\n",
            "\t Validation accuracy for digit 6: 97.78\n",
            "\t Validation accuracy for digit 7: 97.03\n",
            "\t Validation accuracy for digit 8: 91.64\n",
            "\t Validation accuracy for digit 9: 90.57\n",
            "epoch 4, batch: 10, training loss: 0.117\n",
            "epoch 4, batch: 20, training loss: 0.130\n",
            "epoch 4, batch: 30, training loss: 0.135\n",
            "epoch 4, batch: 40, training loss: 0.125\n",
            "epoch 4, batch: 50, training loss: 0.113\n",
            "epoch 4, batch: 60, training loss: 0.124\n",
            "epoch 4, batch: 70, training loss: 0.135\n",
            "epoch 4, batch: 80, training loss: 0.145\n",
            "epoch 4, batch: 90, training loss: 0.139\n",
            "epoch 4, batch: 100, training loss: 0.140\n",
            "epoch 4, batch: 110, training loss: 0.112\n",
            "epoch 4, batch: 120, training loss: 0.150\n",
            "epoch 4, batch: 130, training loss: 0.141\n",
            "epoch 4, batch: 140, training loss: 0.099\n",
            "epoch 4, batch: 150, training loss: 0.141\n",
            "epoch 4, batch: 160, training loss: 0.133\n",
            "epoch 4, batch: 170, training loss: 0.108\n",
            "epoch 4, batch: 180, training loss: 0.117\n",
            "epoch 4, batch: 190, training loss: 0.120\n",
            "epoch 4, batch: 200, training loss: 0.111\n",
            "epoch 4, batch: 210, training loss: 0.081\n",
            "\t Validation accuracy for digit 0: 98.98\n",
            "\t Validation accuracy for digit 1: 98.66\n",
            "\t Validation accuracy for digit 2: 96.21\n",
            "\t Validation accuracy for digit 3: 94.46\n",
            "\t Validation accuracy for digit 4: 98.03\n",
            "\t Validation accuracy for digit 5: 94.33\n",
            "\t Validation accuracy for digit 6: 97.14\n",
            "\t Validation accuracy for digit 7: 93.47\n",
            "\t Validation accuracy for digit 8: 94.91\n",
            "\t Validation accuracy for digit 9: 95.62\n",
            "epoch 5, batch: 10, training loss: 0.169\n",
            "epoch 5, batch: 20, training loss: 0.121\n",
            "epoch 5, batch: 30, training loss: 0.058\n",
            "epoch 5, batch: 40, training loss: 0.119\n",
            "epoch 5, batch: 50, training loss: 0.083\n",
            "epoch 5, batch: 60, training loss: 0.074\n",
            "epoch 5, batch: 70, training loss: 0.051\n",
            "epoch 5, batch: 80, training loss: 0.108\n",
            "epoch 5, batch: 90, training loss: 0.128\n",
            "epoch 5, batch: 100, training loss: 0.115\n",
            "epoch 5, batch: 110, training loss: 0.077\n",
            "epoch 5, batch: 120, training loss: 0.115\n",
            "epoch 5, batch: 130, training loss: 0.074\n",
            "epoch 5, batch: 140, training loss: 0.131\n",
            "epoch 5, batch: 150, training loss: 0.101\n",
            "epoch 5, batch: 160, training loss: 0.093\n",
            "epoch 5, batch: 170, training loss: 0.125\n",
            "epoch 5, batch: 180, training loss: 0.091\n",
            "epoch 5, batch: 190, training loss: 0.108\n",
            "epoch 5, batch: 200, training loss: 0.136\n",
            "epoch 5, batch: 210, training loss: 0.102\n",
            "\t Validation accuracy for digit 0: 98.63\n",
            "\t Validation accuracy for digit 1: 98.33\n",
            "\t Validation accuracy for digit 2: 98.62\n",
            "\t Validation accuracy for digit 3: 93.81\n",
            "\t Validation accuracy for digit 4: 99.02\n",
            "\t Validation accuracy for digit 5: 90.07\n",
            "\t Validation accuracy for digit 6: 96.83\n",
            "\t Validation accuracy for digit 7: 96.74\n",
            "\t Validation accuracy for digit 8: 94.91\n",
            "\t Validation accuracy for digit 9: 96.30\n",
            "epoch 6, batch: 10, training loss: 0.081\n",
            "epoch 6, batch: 20, training loss: 0.090\n",
            "epoch 6, batch: 30, training loss: 0.064\n",
            "epoch 6, batch: 40, training loss: 0.107\n",
            "epoch 6, batch: 50, training loss: 0.110\n",
            "epoch 6, batch: 60, training loss: 0.056\n",
            "epoch 6, batch: 70, training loss: 0.112\n",
            "epoch 6, batch: 80, training loss: 0.048\n",
            "epoch 6, batch: 90, training loss: 0.057\n",
            "epoch 6, batch: 100, training loss: 0.039\n",
            "epoch 6, batch: 110, training loss: 0.107\n",
            "epoch 6, batch: 120, training loss: 0.119\n",
            "epoch 6, batch: 130, training loss: 0.081\n",
            "epoch 6, batch: 140, training loss: 0.062\n",
            "epoch 6, batch: 150, training loss: 0.102\n",
            "epoch 6, batch: 160, training loss: 0.099\n",
            "epoch 6, batch: 170, training loss: 0.112\n",
            "epoch 6, batch: 180, training loss: 0.080\n",
            "epoch 6, batch: 190, training loss: 0.087\n",
            "epoch 6, batch: 200, training loss: 0.074\n",
            "epoch 6, batch: 210, training loss: 0.112\n",
            "\t Validation accuracy for digit 0: 94.20\n",
            "\t Validation accuracy for digit 1: 96.99\n",
            "\t Validation accuracy for digit 2: 95.17\n",
            "\t Validation accuracy for digit 3: 95.44\n",
            "\t Validation accuracy for digit 4: 98.03\n",
            "\t Validation accuracy for digit 5: 97.52\n",
            "\t Validation accuracy for digit 6: 98.73\n",
            "\t Validation accuracy for digit 7: 90.21\n",
            "\t Validation accuracy for digit 8: 96.00\n",
            "\t Validation accuracy for digit 9: 97.31\n",
            "epoch 7, batch: 10, training loss: 0.042\n",
            "epoch 7, batch: 20, training loss: 0.074\n",
            "epoch 7, batch: 30, training loss: 0.108\n",
            "epoch 7, batch: 40, training loss: 0.078\n",
            "epoch 7, batch: 50, training loss: 0.061\n",
            "epoch 7, batch: 60, training loss: 0.059\n",
            "epoch 7, batch: 70, training loss: 0.101\n",
            "epoch 7, batch: 80, training loss: 0.066\n",
            "epoch 7, batch: 90, training loss: 0.069\n",
            "epoch 7, batch: 100, training loss: 0.082\n",
            "epoch 7, batch: 110, training loss: 0.083\n",
            "epoch 7, batch: 120, training loss: 0.038\n",
            "epoch 7, batch: 130, training loss: 0.037\n",
            "epoch 7, batch: 140, training loss: 0.118\n",
            "epoch 7, batch: 150, training loss: 0.059\n",
            "epoch 7, batch: 160, training loss: 0.048\n",
            "epoch 7, batch: 170, training loss: 0.034\n",
            "epoch 7, batch: 180, training loss: 0.025\n",
            "epoch 7, batch: 190, training loss: 0.042\n",
            "epoch 7, batch: 200, training loss: 0.112\n",
            "epoch 7, batch: 210, training loss: 0.061\n",
            "\t Validation accuracy for digit 0: 93.86\n",
            "\t Validation accuracy for digit 1: 99.67\n",
            "\t Validation accuracy for digit 2: 99.31\n",
            "\t Validation accuracy for digit 3: 93.16\n",
            "\t Validation accuracy for digit 4: 99.02\n",
            "\t Validation accuracy for digit 5: 97.16\n",
            "\t Validation accuracy for digit 6: 98.10\n",
            "\t Validation accuracy for digit 7: 97.63\n",
            "\t Validation accuracy for digit 8: 93.45\n",
            "\t Validation accuracy for digit 9: 96.63\n",
            "epoch 8, batch: 10, training loss: 0.052\n",
            "epoch 8, batch: 20, training loss: 0.028\n",
            "epoch 8, batch: 30, training loss: 0.058\n",
            "epoch 8, batch: 40, training loss: 0.036\n",
            "epoch 8, batch: 50, training loss: 0.027\n",
            "epoch 8, batch: 60, training loss: 0.046\n",
            "epoch 8, batch: 70, training loss: 0.052\n",
            "epoch 8, batch: 80, training loss: 0.054\n",
            "epoch 8, batch: 90, training loss: 0.047\n",
            "epoch 8, batch: 100, training loss: 0.037\n",
            "epoch 8, batch: 110, training loss: 0.061\n",
            "epoch 8, batch: 120, training loss: 0.092\n",
            "epoch 8, batch: 130, training loss: 0.080\n",
            "epoch 8, batch: 140, training loss: 0.054\n",
            "epoch 8, batch: 150, training loss: 0.044\n",
            "epoch 8, batch: 160, training loss: 0.052\n",
            "epoch 8, batch: 170, training loss: 0.061\n",
            "epoch 8, batch: 180, training loss: 0.066\n",
            "epoch 8, batch: 190, training loss: 0.068\n",
            "epoch 8, batch: 200, training loss: 0.041\n",
            "epoch 8, batch: 210, training loss: 0.044\n",
            "\t Validation accuracy for digit 0: 98.98\n",
            "\t Validation accuracy for digit 1: 98.66\n",
            "\t Validation accuracy for digit 2: 99.31\n",
            "\t Validation accuracy for digit 3: 94.14\n",
            "\t Validation accuracy for digit 4: 98.69\n",
            "\t Validation accuracy for digit 5: 97.16\n",
            "\t Validation accuracy for digit 6: 97.78\n",
            "\t Validation accuracy for digit 7: 94.96\n",
            "\t Validation accuracy for digit 8: 94.91\n",
            "\t Validation accuracy for digit 9: 97.98\n",
            "epoch 9, batch: 10, training loss: 0.054\n",
            "epoch 9, batch: 20, training loss: 0.040\n",
            "epoch 9, batch: 30, training loss: 0.046\n",
            "epoch 9, batch: 40, training loss: 0.037\n",
            "epoch 9, batch: 50, training loss: 0.018\n",
            "epoch 9, batch: 60, training loss: 0.043\n",
            "epoch 9, batch: 70, training loss: 0.054\n",
            "epoch 9, batch: 80, training loss: 0.044\n",
            "epoch 9, batch: 90, training loss: 0.062\n",
            "epoch 9, batch: 100, training loss: 0.057\n",
            "epoch 9, batch: 110, training loss: 0.041\n",
            "epoch 9, batch: 120, training loss: 0.072\n",
            "epoch 9, batch: 130, training loss: 0.042\n",
            "epoch 9, batch: 140, training loss: 0.047\n",
            "epoch 9, batch: 150, training loss: 0.071\n",
            "epoch 9, batch: 160, training loss: 0.059\n",
            "epoch 9, batch: 170, training loss: 0.053\n",
            "epoch 9, batch: 180, training loss: 0.050\n",
            "epoch 9, batch: 190, training loss: 0.041\n",
            "epoch 9, batch: 200, training loss: 0.068\n",
            "epoch 9, batch: 210, training loss: 0.057\n",
            "\t Validation accuracy for digit 0: 98.98\n",
            "\t Validation accuracy for digit 1: 96.99\n",
            "\t Validation accuracy for digit 2: 98.28\n",
            "\t Validation accuracy for digit 3: 95.11\n",
            "\t Validation accuracy for digit 4: 97.70\n",
            "\t Validation accuracy for digit 5: 95.74\n",
            "\t Validation accuracy for digit 6: 99.37\n",
            "\t Validation accuracy for digit 7: 96.44\n",
            "\t Validation accuracy for digit 8: 96.73\n",
            "\t Validation accuracy for digit 9: 97.64\n",
            "epoch 10, batch: 10, training loss: 0.023\n",
            "epoch 10, batch: 20, training loss: 0.049\n",
            "epoch 10, batch: 30, training loss: 0.034\n",
            "epoch 10, batch: 40, training loss: 0.065\n",
            "epoch 10, batch: 50, training loss: 0.046\n",
            "epoch 10, batch: 60, training loss: 0.055\n",
            "epoch 10, batch: 70, training loss: 0.034\n",
            "epoch 10, batch: 80, training loss: 0.034\n",
            "epoch 10, batch: 90, training loss: 0.064\n",
            "epoch 10, batch: 100, training loss: 0.057\n",
            "epoch 10, batch: 110, training loss: 0.045\n",
            "epoch 10, batch: 120, training loss: 0.015\n",
            "epoch 10, batch: 130, training loss: 0.064\n",
            "epoch 10, batch: 140, training loss: 0.018\n",
            "epoch 10, batch: 150, training loss: 0.021\n",
            "epoch 10, batch: 160, training loss: 0.021\n",
            "epoch 10, batch: 170, training loss: 0.022\n",
            "epoch 10, batch: 180, training loss: 0.023\n",
            "epoch 10, batch: 190, training loss: 0.043\n",
            "epoch 10, batch: 200, training loss: 0.030\n",
            "epoch 10, batch: 210, training loss: 0.037\n",
            "\t Validation accuracy for digit 0: 96.93\n",
            "\t Validation accuracy for digit 1: 99.00\n",
            "\t Validation accuracy for digit 2: 95.86\n",
            "\t Validation accuracy for digit 3: 95.44\n",
            "\t Validation accuracy for digit 4: 97.70\n",
            "\t Validation accuracy for digit 5: 96.81\n",
            "\t Validation accuracy for digit 6: 97.46\n",
            "\t Validation accuracy for digit 7: 98.22\n",
            "\t Validation accuracy for digit 8: 97.82\n",
            "\t Validation accuracy for digit 9: 97.64\n",
            "epoch 11, batch: 10, training loss: 0.024\n",
            "epoch 11, batch: 20, training loss: 0.014\n",
            "epoch 11, batch: 30, training loss: 0.030\n",
            "epoch 11, batch: 40, training loss: 0.026\n",
            "epoch 11, batch: 50, training loss: 0.077\n",
            "epoch 11, batch: 60, training loss: 0.049\n",
            "epoch 11, batch: 70, training loss: 0.043\n",
            "epoch 11, batch: 80, training loss: 0.042\n",
            "epoch 11, batch: 90, training loss: 0.036\n",
            "epoch 11, batch: 100, training loss: 0.035\n",
            "epoch 11, batch: 110, training loss: 0.051\n",
            "epoch 11, batch: 120, training loss: 0.052\n",
            "epoch 11, batch: 130, training loss: 0.022\n",
            "epoch 11, batch: 140, training loss: 0.051\n",
            "epoch 11, batch: 150, training loss: 0.067\n",
            "epoch 11, batch: 160, training loss: 0.040\n",
            "epoch 11, batch: 170, training loss: 0.048\n",
            "epoch 11, batch: 180, training loss: 0.044\n",
            "epoch 11, batch: 190, training loss: 0.038\n",
            "epoch 11, batch: 200, training loss: 0.040\n",
            "epoch 11, batch: 210, training loss: 0.021\n",
            "\t Validation accuracy for digit 0: 98.98\n",
            "\t Validation accuracy for digit 1: 98.66\n",
            "\t Validation accuracy for digit 2: 98.62\n",
            "\t Validation accuracy for digit 3: 96.74\n",
            "\t Validation accuracy for digit 4: 96.72\n",
            "\t Validation accuracy for digit 5: 95.04\n",
            "\t Validation accuracy for digit 6: 95.87\n",
            "\t Validation accuracy for digit 7: 97.33\n",
            "\t Validation accuracy for digit 8: 96.00\n",
            "\t Validation accuracy for digit 9: 98.32\n",
            "epoch 12, batch: 10, training loss: 0.024\n",
            "epoch 12, batch: 20, training loss: 0.034\n",
            "epoch 12, batch: 30, training loss: 0.018\n",
            "epoch 12, batch: 40, training loss: 0.026\n",
            "epoch 12, batch: 50, training loss: 0.042\n",
            "epoch 12, batch: 60, training loss: 0.016\n",
            "epoch 12, batch: 70, training loss: 0.019\n",
            "epoch 12, batch: 80, training loss: 0.038\n",
            "epoch 12, batch: 90, training loss: 0.037\n",
            "epoch 12, batch: 100, training loss: 0.041\n",
            "epoch 12, batch: 110, training loss: 0.052\n",
            "epoch 12, batch: 120, training loss: 0.026\n",
            "epoch 12, batch: 130, training loss: 0.031\n",
            "epoch 12, batch: 140, training loss: 0.017\n",
            "epoch 12, batch: 150, training loss: 0.025\n",
            "epoch 12, batch: 160, training loss: 0.051\n",
            "epoch 12, batch: 170, training loss: 0.033\n",
            "epoch 12, batch: 180, training loss: 0.062\n",
            "epoch 12, batch: 190, training loss: 0.019\n",
            "epoch 12, batch: 200, training loss: 0.049\n",
            "epoch 12, batch: 210, training loss: 0.042\n",
            "\t Validation accuracy for digit 0: 98.29\n",
            "\t Validation accuracy for digit 1: 98.66\n",
            "\t Validation accuracy for digit 2: 98.97\n",
            "\t Validation accuracy for digit 3: 94.46\n",
            "\t Validation accuracy for digit 4: 100.00\n",
            "\t Validation accuracy for digit 5: 94.33\n",
            "\t Validation accuracy for digit 6: 98.10\n",
            "\t Validation accuracy for digit 7: 97.03\n",
            "\t Validation accuracy for digit 8: 94.91\n",
            "\t Validation accuracy for digit 9: 94.61\n",
            "epoch 13, batch: 10, training loss: 0.055\n",
            "epoch 13, batch: 20, training loss: 0.020\n",
            "epoch 13, batch: 30, training loss: 0.015\n",
            "epoch 13, batch: 40, training loss: 0.019\n",
            "epoch 13, batch: 50, training loss: 0.014\n",
            "epoch 13, batch: 60, training loss: 0.027\n",
            "epoch 13, batch: 70, training loss: 0.028\n",
            "epoch 13, batch: 80, training loss: 0.062\n",
            "epoch 13, batch: 90, training loss: 0.034\n",
            "epoch 13, batch: 100, training loss: 0.019\n",
            "epoch 13, batch: 110, training loss: 0.056\n",
            "epoch 13, batch: 120, training loss: 0.047\n",
            "epoch 13, batch: 130, training loss: 0.022\n",
            "epoch 13, batch: 140, training loss: 0.025\n",
            "epoch 13, batch: 150, training loss: 0.023\n",
            "epoch 13, batch: 160, training loss: 0.021\n",
            "epoch 13, batch: 170, training loss: 0.052\n",
            "epoch 13, batch: 180, training loss: 0.080\n",
            "epoch 13, batch: 190, training loss: 0.018\n",
            "epoch 13, batch: 200, training loss: 0.027\n",
            "epoch 13, batch: 210, training loss: 0.018\n",
            "\t Validation accuracy for digit 0: 97.95\n",
            "\t Validation accuracy for digit 1: 99.67\n",
            "\t Validation accuracy for digit 2: 98.28\n",
            "\t Validation accuracy for digit 3: 94.79\n",
            "\t Validation accuracy for digit 4: 98.69\n",
            "\t Validation accuracy for digit 5: 97.52\n",
            "\t Validation accuracy for digit 6: 98.10\n",
            "\t Validation accuracy for digit 7: 98.81\n",
            "\t Validation accuracy for digit 8: 96.00\n",
            "\t Validation accuracy for digit 9: 97.31\n",
            "epoch 14, batch: 10, training loss: 0.009\n",
            "epoch 14, batch: 20, training loss: 0.009\n",
            "epoch 14, batch: 30, training loss: 0.021\n",
            "epoch 14, batch: 40, training loss: 0.014\n",
            "epoch 14, batch: 50, training loss: 0.016\n",
            "epoch 14, batch: 60, training loss: 0.010\n",
            "epoch 14, batch: 70, training loss: 0.007\n",
            "epoch 14, batch: 80, training loss: 0.014\n",
            "epoch 14, batch: 90, training loss: 0.003\n",
            "epoch 14, batch: 100, training loss: 0.016\n",
            "epoch 14, batch: 110, training loss: 0.023\n",
            "epoch 14, batch: 120, training loss: 0.006\n",
            "epoch 14, batch: 130, training loss: 0.028\n",
            "epoch 14, batch: 140, training loss: 0.017\n",
            "epoch 14, batch: 150, training loss: 0.014\n",
            "epoch 14, batch: 160, training loss: 0.028\n",
            "epoch 14, batch: 170, training loss: 0.024\n",
            "epoch 14, batch: 180, training loss: 0.019\n",
            "epoch 14, batch: 190, training loss: 0.037\n",
            "epoch 14, batch: 200, training loss: 0.025\n",
            "epoch 14, batch: 210, training loss: 0.009\n",
            "\t Validation accuracy for digit 0: 98.98\n",
            "\t Validation accuracy for digit 1: 99.67\n",
            "\t Validation accuracy for digit 2: 97.93\n",
            "\t Validation accuracy for digit 3: 92.51\n",
            "\t Validation accuracy for digit 4: 98.36\n",
            "\t Validation accuracy for digit 5: 97.16\n",
            "\t Validation accuracy for digit 6: 98.73\n",
            "\t Validation accuracy for digit 7: 97.03\n",
            "\t Validation accuracy for digit 8: 96.36\n",
            "\t Validation accuracy for digit 9: 98.65\n",
            "epoch 15, batch: 10, training loss: 0.020\n",
            "epoch 15, batch: 20, training loss: 0.020\n",
            "epoch 15, batch: 30, training loss: 0.018\n",
            "epoch 15, batch: 40, training loss: 0.034\n",
            "epoch 15, batch: 50, training loss: 0.054\n",
            "epoch 15, batch: 60, training loss: 0.033\n",
            "epoch 15, batch: 70, training loss: 0.036\n",
            "epoch 15, batch: 80, training loss: 0.016\n",
            "epoch 15, batch: 90, training loss: 0.016\n",
            "epoch 15, batch: 100, training loss: 0.008\n",
            "epoch 15, batch: 110, training loss: 0.007\n",
            "epoch 15, batch: 120, training loss: 0.005\n",
            "epoch 15, batch: 130, training loss: 0.018\n",
            "epoch 15, batch: 140, training loss: 0.013\n",
            "epoch 15, batch: 150, training loss: 0.029\n",
            "epoch 15, batch: 160, training loss: 0.022\n",
            "epoch 15, batch: 170, training loss: 0.033\n",
            "epoch 15, batch: 180, training loss: 0.044\n",
            "epoch 15, batch: 190, training loss: 0.024\n",
            "epoch 15, batch: 200, training loss: 0.020\n",
            "epoch 15, batch: 210, training loss: 0.021\n",
            "\t Validation accuracy for digit 0: 95.56\n",
            "\t Validation accuracy for digit 1: 99.33\n",
            "\t Validation accuracy for digit 2: 97.59\n",
            "\t Validation accuracy for digit 3: 95.44\n",
            "\t Validation accuracy for digit 4: 95.41\n",
            "\t Validation accuracy for digit 5: 97.87\n",
            "\t Validation accuracy for digit 6: 98.41\n",
            "\t Validation accuracy for digit 7: 95.85\n",
            "\t Validation accuracy for digit 8: 97.09\n",
            "\t Validation accuracy for digit 9: 98.32\n",
            "epoch 16, batch: 10, training loss: 0.016\n",
            "epoch 16, batch: 20, training loss: 0.046\n",
            "epoch 16, batch: 30, training loss: 0.016\n",
            "epoch 16, batch: 40, training loss: 0.011\n",
            "epoch 16, batch: 50, training loss: 0.014\n",
            "epoch 16, batch: 60, training loss: 0.015\n",
            "epoch 16, batch: 70, training loss: 0.005\n",
            "epoch 16, batch: 80, training loss: 0.011\n",
            "epoch 16, batch: 90, training loss: 0.007\n",
            "epoch 16, batch: 100, training loss: 0.008\n",
            "epoch 16, batch: 110, training loss: 0.011\n",
            "epoch 16, batch: 120, training loss: 0.007\n",
            "epoch 16, batch: 130, training loss: 0.019\n",
            "epoch 16, batch: 140, training loss: 0.014\n",
            "epoch 16, batch: 150, training loss: 0.017\n",
            "epoch 16, batch: 160, training loss: 0.014\n",
            "epoch 16, batch: 170, training loss: 0.025\n",
            "epoch 16, batch: 180, training loss: 0.006\n",
            "epoch 16, batch: 190, training loss: 0.008\n",
            "epoch 16, batch: 200, training loss: 0.037\n",
            "epoch 16, batch: 210, training loss: 0.043\n",
            "\t Validation accuracy for digit 0: 94.88\n",
            "\t Validation accuracy for digit 1: 96.66\n",
            "\t Validation accuracy for digit 2: 97.93\n",
            "\t Validation accuracy for digit 3: 91.53\n",
            "\t Validation accuracy for digit 4: 97.70\n",
            "\t Validation accuracy for digit 5: 98.94\n",
            "\t Validation accuracy for digit 6: 99.05\n",
            "\t Validation accuracy for digit 7: 95.85\n",
            "\t Validation accuracy for digit 8: 96.73\n",
            "\t Validation accuracy for digit 9: 94.28\n",
            "epoch 17, batch: 10, training loss: 0.038\n",
            "epoch 17, batch: 20, training loss: 0.037\n",
            "epoch 17, batch: 30, training loss: 0.012\n",
            "epoch 17, batch: 40, training loss: 0.028\n",
            "epoch 17, batch: 50, training loss: 0.011\n",
            "epoch 17, batch: 60, training loss: 0.010\n",
            "epoch 17, batch: 70, training loss: 0.014\n",
            "epoch 17, batch: 80, training loss: 0.010\n",
            "epoch 17, batch: 90, training loss: 0.006\n",
            "epoch 17, batch: 100, training loss: 0.011\n",
            "epoch 17, batch: 110, training loss: 0.022\n",
            "epoch 17, batch: 120, training loss: 0.003\n",
            "epoch 17, batch: 130, training loss: 0.011\n",
            "epoch 17, batch: 140, training loss: 0.006\n",
            "epoch 17, batch: 150, training loss: 0.002\n",
            "epoch 17, batch: 160, training loss: 0.010\n",
            "epoch 17, batch: 170, training loss: 0.009\n",
            "epoch 17, batch: 180, training loss: 0.011\n",
            "epoch 17, batch: 190, training loss: 0.008\n",
            "epoch 17, batch: 200, training loss: 0.009\n",
            "epoch 17, batch: 210, training loss: 0.010\n",
            "\t Validation accuracy for digit 0: 98.63\n",
            "\t Validation accuracy for digit 1: 98.33\n",
            "\t Validation accuracy for digit 2: 99.66\n",
            "\t Validation accuracy for digit 3: 94.79\n",
            "\t Validation accuracy for digit 4: 95.74\n",
            "\t Validation accuracy for digit 5: 95.39\n",
            "\t Validation accuracy for digit 6: 98.10\n",
            "\t Validation accuracy for digit 7: 99.11\n",
            "\t Validation accuracy for digit 8: 95.64\n",
            "\t Validation accuracy for digit 9: 98.65\n",
            "epoch 18, batch: 10, training loss: 0.007\n",
            "epoch 18, batch: 20, training loss: 0.021\n",
            "epoch 18, batch: 30, training loss: 0.019\n",
            "epoch 18, batch: 40, training loss: 0.008\n",
            "epoch 18, batch: 50, training loss: 0.011\n",
            "epoch 18, batch: 60, training loss: 0.013\n",
            "epoch 18, batch: 70, training loss: 0.004\n",
            "epoch 18, batch: 80, training loss: 0.004\n",
            "epoch 18, batch: 90, training loss: 0.003\n",
            "epoch 18, batch: 100, training loss: 0.006\n",
            "epoch 18, batch: 110, training loss: 0.002\n",
            "epoch 18, batch: 120, training loss: 0.006\n",
            "epoch 18, batch: 130, training loss: 0.009\n",
            "epoch 18, batch: 140, training loss: 0.005\n",
            "epoch 18, batch: 150, training loss: 0.006\n",
            "epoch 18, batch: 160, training loss: 0.004\n",
            "epoch 18, batch: 170, training loss: 0.002\n",
            "epoch 18, batch: 180, training loss: 0.007\n",
            "epoch 18, batch: 190, training loss: 0.009\n",
            "epoch 18, batch: 200, training loss: 0.006\n",
            "epoch 18, batch: 210, training loss: 0.002\n",
            "\t Validation accuracy for digit 0: 97.61\n",
            "\t Validation accuracy for digit 1: 99.67\n",
            "\t Validation accuracy for digit 2: 98.97\n",
            "\t Validation accuracy for digit 3: 96.09\n",
            "\t Validation accuracy for digit 4: 98.36\n",
            "\t Validation accuracy for digit 5: 96.81\n",
            "\t Validation accuracy for digit 6: 98.73\n",
            "\t Validation accuracy for digit 7: 99.11\n",
            "\t Validation accuracy for digit 8: 96.73\n",
            "\t Validation accuracy for digit 9: 98.65\n",
            "epoch 19, batch: 10, training loss: 0.001\n",
            "epoch 19, batch: 20, training loss: 0.002\n",
            "epoch 19, batch: 30, training loss: 0.001\n",
            "epoch 19, batch: 40, training loss: 0.001\n",
            "epoch 19, batch: 50, training loss: 0.002\n",
            "epoch 19, batch: 60, training loss: 0.005\n",
            "epoch 19, batch: 70, training loss: 0.004\n",
            "epoch 19, batch: 80, training loss: 0.005\n",
            "epoch 19, batch: 90, training loss: 0.003\n",
            "epoch 19, batch: 100, training loss: 0.007\n",
            "epoch 19, batch: 110, training loss: 0.007\n",
            "epoch 19, batch: 120, training loss: 0.016\n",
            "epoch 19, batch: 130, training loss: 0.020\n",
            "epoch 19, batch: 140, training loss: 0.024\n",
            "epoch 19, batch: 150, training loss: 0.016\n",
            "epoch 19, batch: 160, training loss: 0.015\n",
            "epoch 19, batch: 170, training loss: 0.016\n",
            "epoch 19, batch: 180, training loss: 0.023\n",
            "epoch 19, batch: 190, training loss: 0.015\n",
            "epoch 19, batch: 200, training loss: 0.009\n",
            "epoch 19, batch: 210, training loss: 0.017\n",
            "\t Validation accuracy for digit 0: 98.63\n",
            "\t Validation accuracy for digit 1: 96.99\n",
            "\t Validation accuracy for digit 2: 96.90\n",
            "\t Validation accuracy for digit 3: 98.37\n",
            "\t Validation accuracy for digit 4: 98.69\n",
            "\t Validation accuracy for digit 5: 97.16\n",
            "\t Validation accuracy for digit 6: 97.78\n",
            "\t Validation accuracy for digit 7: 95.25\n",
            "\t Validation accuracy for digit 8: 97.45\n",
            "\t Validation accuracy for digit 9: 97.31\n",
            "epoch 20, batch: 10, training loss: 0.013\n",
            "epoch 20, batch: 20, training loss: 0.032\n",
            "epoch 20, batch: 30, training loss: 0.026\n",
            "epoch 20, batch: 40, training loss: 0.024\n",
            "epoch 20, batch: 50, training loss: 0.037\n",
            "epoch 20, batch: 60, training loss: 0.008\n",
            "epoch 20, batch: 70, training loss: 0.016\n",
            "epoch 20, batch: 80, training loss: 0.007\n",
            "epoch 20, batch: 90, training loss: 0.019\n",
            "epoch 20, batch: 100, training loss: 0.012\n",
            "epoch 20, batch: 110, training loss: 0.013\n",
            "epoch 20, batch: 120, training loss: 0.012\n",
            "epoch 20, batch: 130, training loss: 0.003\n",
            "epoch 20, batch: 140, training loss: 0.012\n",
            "epoch 20, batch: 150, training loss: 0.007\n",
            "epoch 20, batch: 160, training loss: 0.015\n",
            "epoch 20, batch: 170, training loss: 0.010\n",
            "epoch 20, batch: 180, training loss: 0.028\n",
            "epoch 20, batch: 190, training loss: 0.012\n",
            "epoch 20, batch: 200, training loss: 0.021\n",
            "epoch 20, batch: 210, training loss: 0.040\n",
            "\t Validation accuracy for digit 0: 98.29\n",
            "\t Validation accuracy for digit 1: 98.33\n",
            "\t Validation accuracy for digit 2: 98.28\n",
            "\t Validation accuracy for digit 3: 88.93\n",
            "\t Validation accuracy for digit 4: 97.38\n",
            "\t Validation accuracy for digit 5: 97.16\n",
            "\t Validation accuracy for digit 6: 99.68\n",
            "\t Validation accuracy for digit 7: 96.14\n",
            "\t Validation accuracy for digit 8: 94.91\n",
            "\t Validation accuracy for digit 9: 98.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnOgAjMNe6DY"
      },
      "source": [
        "  "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Ee8p1Vtjw5"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdxNieFbktAp"
      },
      "source": [
        " "
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}